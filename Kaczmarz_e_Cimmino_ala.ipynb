{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "UNIVERSIDADE FEDERAL DE SANTA CATARINA.<br>\n",
    "Alunos: João Guilheme Voss e Tainá da Silva.<br>\n",
    "Componente curricular: Álgebra linear aplicada. <br>\n",
    "Orientador: Luiz Rafael dos Santos. <br>\n",
    "Blumenau.<br>\n",
    "2020.</p><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Resolução de sistema linear por projeções olhando para as linhas do sistema linear  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Introdução </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"> Parte dos problemas de matemática computacional se resume à solução numérica de sistemas lineares, muitas vezes de dimensões muito grandes. Após uma possível discretização, esses problemas são reduzidos a sistemas lineares da forma $Ax = b$ em que $A$ é um matriz grande e esparsa e $b$ um determinado vetor do lado direito do sistema.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"> Desta forma, faz sentido a busca pelo aprimoramento e busca de algoritmos numéricos cada vez mais rápidos e eficazes. Com o tempo, um grande número de técnicas foram desenvolvidos para resolver sistemas lineares. Esses métodos são tradicionalmente agrupados em duas categorias principais: os métodos diretos, que (exceto em erros de arredondamento) garantem o retorno exato da solução $x_{∗} = A^{−1} b$ em um número finito de etapas; e métodos iterativos, que produzem uma sequência de aproximações sucessivas $x^{(k)}$ que, sob as condições apropriadas, convergem para $x_{∗}$ com $k \\rightarrow \\infty$.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"> Alguns exemplos de métodos diretos são a eliminação de Gauss, a fatoração de Cholesky e processos de ortogonalização. Esses algoritmos são ótimos para encontrar a solução de sistemas lineares de pequeno ou moderado tamanho. Os métodos iterativos são mais adequados para resolver sistemas lineares de grande escala.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"> Este trabalho abordará dois métodos iterativos, o método de Kaczmarz e o método de Cimmino, trazendo um breve contexto histórico de suas produções, descrevendo o funcionamento dos algoritmos e implementando-os computacionalmente.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"> Antes de abordamos os métodos de Kaczmarz e Cimmino, precisamos construir e relembrar algumas ferramentas matemáticas que vão nos ajudar a compreender melhor estes métodos. Desta forma, nesta seção vamos definir, enunciar e demonstrar conceitos fundamentais para a compreensão dos métodos abordados. Para tal, usaremos como referência (MEYER, 2000) e (CERQUEIRA, 2013).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Conceitos básicos </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>Definição 1 </strong> Um espaço afim $v + \\mathcal{M}$, em que $dim(\\mathcal{M}) = m-1$ é dito um hiperplano. A $i$-ésima equação de um sistema linear $Ax=b$, $A \\in \\mathbb{R}^{m \\times n}$, isto é, $A_{i*}x = b_i$ é um hiperplano em $\\mathbb{R}^{m}$. Desta forma, a solução do sistema se encontra na intersecção dos $m$ hiperplanos definidos pelas linhas de $A$. É possível fazer as seguintes afirmações:</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>i)</strong> Dado um escalar $\\beta$ e um vetor não-nulo $u$, o conjunto $\\mathcal{H}= \\{ x \\mid u^{T}x= \\beta\\}$ é um hiperplano em $\\mathbb{R}^{m}$.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>ii)</strong> A projeção ortogonal de $b \\in \\mathbb{R}^{m}$ sobre $\\mathcal{H}$ é $p=b-(\\frac{u^{T}b - \\beta}{u^{T}u})u$.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>Definição 2 </strong> Para $u_{n \\times 1} \\neq 0$, a reflexão elementar sobre $u^{\\perp}$ é dada por\n",
    "\n",
    "$$ R = I - 2\\frac{uu^{T}}{u^{T}u}, $$ ou\n",
    "\n",
    "$$R = I - 2uu^{T},$$\n",
    "\n",
    "quando $\\Vert u \\Vert_{2} = 1$.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>Definição 3 </strong>Uma sequência $(a_{n})$ é dita monótona decrescente se $a_{n} > a_{n+1}$.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center; font-family:courier,arial,helvetica;\"> Método das projeções de Kaczmarz </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"> O método foi criado pelo polonês Stefan Kaczmarz no ano de 1937. O algoritmo utiliza, a cada passo, uma equação do sistema $Ax=b$, de forma ordenada.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"> \"O método de Kaczmarz clássico, também conhecido como Técnica de Reconstrução Algébrica (ART - Algebraic Reconstruction Technique), é um algoritmo iterativo para solucionar sistemas do tipo $Ax = b$ que age realizando operações nas linhas da matriz $A$ (ESTACIO, 2014, p.34).\"</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"> \"Utilizando uma equação da matriz $A$ por vez e atualizando a solução aproximada corrente $(x_{k})$ a cada iteração o método converge para a solução deste sistema linear caso ele seja consistente. E, caso o sistema seja inconsistente, o algoritmo converge até uma região próxima a interseção entre os hiperplanos e, não necessariamente, a uma solução de mínimos quadrados\" (ESTACIO, 2014, p.34).\" </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A solução do sitema linear não-singular </p>\n",
    "<p>\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    a_{11} & a_{12}\\\\\n",
    "    a_{21} & a_{22}     \n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "x_{1}\\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "b_{1}\\\\\n",
    "b_{2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "</p>\n",
    "<p> é a intersecção de dois hiperplanos (neste caso duas retas) definidos por </p>\n",
    "\n",
    "$$\n",
    "\\mathcal{H}_{1} = \\{(x_{1}, x_{2}) \\mid a_{11} \\cdot x_{1} + a_{12} \\cdot x_{2} = b_{1}\\} \\hbox{ e } \\mathcal{H}_{2} = \\{(x_{1}, x_{2}) \\mid a_{21} \\cdot x_{1} + a_{22} \\cdot x_{2} = b_{2}\\}.\n",
    "$$\n",
    "\n",
    "<p> É visualmente evidente que, começando com um ponto arbitrário $P_{0}$ e realizando uma squência de projeções ortogonais alternadas em $\\mathcal{H}_{1}$ e $\\mathcal{H}_{2}$ como representado na figura abaixo, a sequência resultante de projeções $\\{p_{1}, p_{2}, p_{3}, p_{4}, \\ldots \\}$ converge para $\\mathcal{H}_{1}\\cap \\mathcal{H}_{2}$, que é a solução de $Ax=b$.</p>\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagem](https://i.ibb.co/BBRs4cs/kaczmarzs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Essa idéia pode ser generalizada usando a <strong> Definição 1 </strong>. </p>\n",
    "<p> Para um sistema consistente $A_{n \\times r}x=b$ em que $rank(A)=r$, escale as linhas de modo que $\\| A_{i*}\\|_{2} = 1$ para todo $i$, em que $\\mathcal{H}_{i}=\\{ x \\mid A_{i*}x = b_{i}\\}$ é o hiperplano definido pela i-ésima equação. </p>\n",
    "    \n",
    "<p> Comece com um vetor arbitrário $p_{0} \\in \\mathbb{R}^{r \\times 1}$, e sucessivamente realizar projeções ortogonais em cada hiperplano para gerar a seguinte sequência: </p>\n",
    "    \n",
    "$$ p_{1} = p_{0} - (A_{1*}p_{0} - b_{1})(A_{1*})^{T} \\hbox{ (Projeção do ponto $p_{0}$ em $\\mathcal{H}_{1}$)} $$\n",
    "$$ p_{2} = p_{1} - (A_{2*}p_{1} - b_{2})(A_{2*})^{T} \\hbox{ (Projeção do ponto $p_{1}$ em $\\mathcal{H}_{2}$)} $$\n",
    "$$ \\vdots $$\n",
    "$$ p_{n} = p_{n-1} - (A_{n*}p_{n-1} - b_{n})(A_{n*})^{T} \\hbox{ (Projeção do ponto $p_{n-1}$ em $\\mathcal{H}_{n}$)} $$\n",
    "    \n",
    "<p> Quando todos os $n$ hiperplanos tiverem sido usados, continue repetindo o processo. Por exemplo, na segunda passagem projete $p_{n}$ em $\\mathcal{H}_{1}$; então projete $p_{n+1}$ em $\\mathcal{H}_{2}$, etc. Para um $p_{0}$ arbitrário, toda a sequência de Kaczmarz é gerada executando o seguinte loop duplo: </p>   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "For $k = 0, 1, 2, 3, \\ldots$ <br>\n",
    "$\\hbox{ }$ $\\hbox{ }$ For $i = 1, 2, \\ldots, n$ <br>\n",
    "$\\hbox{ }$ $\\hbox{ }$ $\\hbox{ }$ $\\hbox{ }$ $p_{kn+i} = p_{kn+i-1} - (A_{i*}p_{kn+i-1}-b_{i})(A_{i*})^{T}$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Provaremos que a sequência de Kaczmarz converge para a solução de $Ax = b$ mostrando $\\|p_{kn+i}-x\\|_{2}^{2} = \\|p_{kn+i-1}-x\\|_{2}^{2} - (A_{i*}p_{kn+i-1}-b_{i})^{2}$ \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Demonstação </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Por conveniência defina $\\beta = A_{i*}p_{kn+i-1}-b_{i}$ de forma que, de acordo com a sequência de passos do algoritmo temos $p_{kn+i}=p_{kn+i-1} - \\beta(A_{i*})^{T}$. </p>\n",
    "\n",
    "<p >Também utilizaremos o seguinte fato $A_{i*} (p_{kn+i-1} - x) = A_{i*} p_{kn+i-1} - b_{i} = \\beta$, junto com $\\| A_{i*} \\|^{2}_{2} = 1$ de forma a escrever</p>\n",
    "\n",
    "<p>\\begin{align}\n",
    "    \\|p_{kn+i}-x \\|^{2}_{2} &= \\| p_{kn+i-1} - \\beta(A_{i*})^{T} - x \\|^{2}_{2} \\\\\n",
    "    &=\\| (p_{kn+i-1} - x) - \\beta(A_{i*})^{T} \\|^{2}_{2} \\\\\n",
    "    &= (p_{kn+i-1} - x)^{T} (p_{kn+i-1} - x) - 2 \\beta A_{i*} (p_{kn+i-1} - x) + \\beta^{2}A_{i*}(A_{i*})^{T}\\\\\n",
    "    &= \\|p_{kn+i-1}-x \\|^{2}_{2} - \\beta^{2}.\n",
    "\\end{align}</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">Consequentemente, observamos que $\\|p_{kn+i}-x \\|_{2} \\leq \\|p_{kn+i-1}-x \\|_{2}$. A igualdade vale se, e somente se, $\\beta = 0$, ou de maneira equivalente, se, e somente se, $p_{kn+i-1} \\in \\mathcal{H}_{i-1} \\cap \\mathcal{H}_{i}$. Conclui-se que a sequência de normas $\\|p_{kn+i}-x \\|_{2}$ é monótona decrescente, e desta forma possui um valor limitante. Isto implica que sequência de $\\beta$'s definida anteriormente deve tender a 0, e desta forma a sequência de $p_{kn+i}$'s converge para $x$.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Implementação Computacional </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora programar o método de Kaczmarz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_matriz (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra, Random, BenchmarkTools\n",
    "Random.seed!(3)\n",
    "\n",
    "n=111\n",
    "r=200\n",
    "A = randn(n,r)\n",
    "b = randn(n)\n",
    "\n",
    "#Primeiro precisamos fazer uma função que normalize as linhas da matriz A\n",
    "\n",
    "function normalize_matriz(A,b)\n",
    "    n,r = size(A)\n",
    "   for i=1:n\n",
    "        β = norm(A[i,:])\n",
    "        A[i,:] = A[i,:]/β\n",
    "        b[i] = b[i]/β\n",
    "    end\n",
    "    return A,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.08227504491331458 -0.051033080187231815 … 0.009360346896866486 -0.1289240445494274; -0.17415962205410643 -0.0317570498699207 … 0.05030432371751788 0.03669618160794412; … ; -0.04161504002723339 0.07401924665759382 … 0.02268924030040744 0.020563285432693958; 0.0037828033068594102 0.06320542960759656 … -0.08086487663737166 0.002611906213386032], [0.004213713942573764, -0.1030658262348759, -0.03755113623378692, 0.07674619912234647, -0.18634981347964633, 0.03861023652440637, -0.008007120855264257, 0.05170084116818933, 0.11137106346952008, -0.11215673208410686  …  0.02651298707610057, 0.06668003086891013, -0.02220700562066386, 0.018293964797876233, 0.07788315422933645, 0.04801524651446222, 0.02577194744366872, 0.0006900105198283498, -0.07729598025572558, 0.050838575788523355])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,b = normalize_matriz(A,b) #Teste da função que normaliza as linhas de A e recalcula o vetor b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proj (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Então, precisamos fazer uma função de projeção\n",
    "function proj(p₀, u, β) \n",
    "    \n",
    "   return  p₀ - ((dot(u, p₀)- β)/dot(u, u))*u\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kaczmarz (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Por fim fazemos o algoritmo de kaczmars utilizando a função de normalização e a de projeção\n",
    "function Kaczmarz(A, b; itmax=10000, ε= 1e-3)\n",
    "   n,r = size(A) \n",
    "    pₖ = ones(r)\n",
    "    k = 1 \n",
    "    A,b = normalize_matriz(A,b)\n",
    "    tol = norm(b- A*pₖ)\n",
    "    while k <= itmax && tol> ε   \n",
    "    for i=1:n\n",
    "         pₖ= proj(pₖ, A[i,:], b[i])\n",
    "    end\n",
    "        tol = norm(b- A*pₖ)\n",
    "        k += 1\n",
    "    end\n",
    "    \n",
    "    return pₖ, tol, k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07236108286869108, -0.038981905328793795, 0.1247544994543753, -0.2781786847646894, 1.1269185531232773, 0.7920657523442465, 0.3366146429021169, 0.1310469531790253, 0.07387319011759072, 0.7301552060638365  …  -0.1938331017727638, 0.618048719641267, 0.818304559717926, 0.31701142293528206, 1.2999397012828706, 0.5536947415729251, 0.3724958520258859, -0.2605235865944006, -0.34223083956496925, 1.2246465445148966], 8.864136207851315e-7, 77)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kaczmarz(A, b, ε=1e-6) #Teste da função que implementa o método iterativo de Kaczmarz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center; font-family:courier,arial,helvetica;\"> Método de reflexão de Cimmino </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\">O método de Cimmino é um  método iterativo para solução de sistemas lineares, foi publicado em 1938 pelo matemático italiano Gianfranco Cimmino (1908-1989), estudante de Mauro Picone. O algoritmo usa simultaneamente todas as equações do sistema linear a cada passo iterativo.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">Segundo Benzi (2004, p.6), o método data de pelo menos 1932 e é possível que Cimmino nunca se preocupou em publicá-lo se não pela insistência de Picone. É provável que Cimmino estava ocupado com sua pesquisa [...] e relutante a dedicar seu tempo para escrever sobre um tópico considerado de menor importância.</p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">\"Os métodos de Cimmino e Kaczmarz são proximamente relacionados. O algoritmo de Cimmino se provou ser melhor formatado para computadores paralelos, enquanto o método de Kaczmarz tende a convergir mais rapidamente\" (BENZI, 2004, p.8).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"> O matemático italiano Gianfranco Cimmino usou a seguinte observação elementar para construir um algoritmo iterativo para resolver sistemas lineares. Para um sistema $2 \\times 2$ tem $Ax = b$, sejam $\\mathcal{H}_{1}$ e $\\mathcal{H}_{2}$ as duas retas (hiperplanos) definidas pelas duas equações. Para um palpite arbitrário $r_{0}$, seja $r_{1}$ o reflexão de $r_{0}$ sobre a linha $\\mathcal{H}_{1}$, e seja $r_{2}$ o reflexão de $r_{0}$ sobre a linha $\\mathcal{H}_{2}$. Conforme ilustrado na abaixo, os três pontos $r_{0}$, $r_{1}$ e $r_{2}$ encontram-se em um círculo cujo centro é $\\mathcal{H}_{1} \\cap \\mathcal{H}_{2}$ (a solução do sistema). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagem](https://i.ibb.co/CMrVJfc/cimmino.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"> O valor médio $m = \\frac{(r_{1} + r_{2})}{2}$ está estritamente dentro do círculo, então $m$ é uma melhor aproximação da solução do que $r_{0}$. É visualmente evidente que iteração produz uma sequência que converge para a solução de $Ax = b$. Provaremos isso em geral usando o esquema a seguir. </p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>a)</strong> Para um escalar $\\beta$ e um vetor $u \\in \\mathbb{R}^{n}$ tal que $\\|u\\|_{2} = 1$, considere o hiperplano $\\mathcal{H}= \\{x \\mid u^{T}x = \\beta\\}$. Usaremos a <strong> Definição 2 </strong> para mostrar que a reflexão de um vetor $b$ sobre $\\mathcal{H}$ é $r=b-2(u^{T}b - \\beta)u$. </p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>b)</strong> Para um sistema $Ax = b$ em que as linhas de $A \\in R^{n \\times r}$ foram escalonadas de forma que $\\|A_{i∗}\\|^{2} = 1$ para todo $i$, seja $\\mathcal{H}_{i}=\\{x \\mid A_{i∗}x=b_{i}\\}$ o hiperplano definido pela $i$-ésima equação. Se $r_{0} \\in \\mathbb{R}^{r \\times 1}$ é um vetor arbitrário, e se $r_{i}$ é a reflexão de $r_{0}$ sobre $\\mathcal{H}_{i}$, explicaremos por que o valor médio das reflexões $\\{r_{1}, r_{2}, \\ldots, r_{n}\\}$ é $m=r_{0} - (\\frac{2}{n})A^{T}\\varepsilon$, em que $\\varepsilon = Ar_{0}-b$. </p>\n",
    "\n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>c)</strong> A iteração da parte <strong>b.</strong> produz $m_{k}=m_{k−1}-\\frac{2}{n}A^{T}\\varepsilon_{k − 1}$, em que $\\varepsilon_{k−1} = Am_{k−1}-b$. Mostraremos que se $A$ é não-singular, e se $x=A^{−1}b$, então $x-m_{k}=(I-\\frac{2}{n}A^{T}A)^{k}(x-m_{0})$. <strong>Nota:</strong> Pode ser provado que se $(I-\\frac{2}{n} A^{T}A)^{k} \\rightarrow 0$ quando $k \\rightarrow \\infty$, então $m_{k} \\rightarrow x$ para qualquer $m_{0}$ escolhido. Na verdade, $m_{k}$ converge mesmo se o  posto $A$ for deficiente - se consistente, ele converge para uma solução e, se inconsistente, o limite é uma solução de mínimos quadrados. Método de Cimmino também funciona com ponderado\n",
    "significa. Se $W = diag (w_{1}, w_{2}, \\ldots, w_{n})$, em que $w_{i}> 0$ e $w_{i}=1$, então $m_{k}=m_{k−1}-\\omega A^{T}W \\varepsilon_{k−1}$ é uma sequência convergente em que $0 < \\omega < 2$ é um “relaxamento parâmetro” que pode ser ajustado para alterar a taxa de convergência. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Demonstração </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>a)</strong> Como já definido anteriormente temos $\\mathcal{H} = v + u^{\\perp}$, em que $v = \\beta u$. Então, subtraindo $v$ de todos os termos no hiperplano $\\mathcal{H}$ e também da solução $b$ transladamos o hiperplano para a origem. Como mostrado na figura abaixo, este processo move $\\mathcal{H}$ para $u^{\\perp}$ e translada $b$ para $b-v$ e $r$ para $r-v$.</p>\n",
    "    \n",
    "<p style=\"text-align: justify; text-justify: inter-word\">Utilizando reflexões de Householder, sabemos que a reflexão de $b-v$ sobre $u^{\\perp}$ é $r -v = R(b-v)=(I -2uu^{T})(b-v)= b+ (\\beta - 2u^{T}b)u$.</p>\n",
    "    \n",
    "<p style=\"text-align: justify; text-justify: inter-word\">Portanto, a reflexão de $b$ sobre $\\mathcal{H}$ é $r = R(b-v)+v=b-2(u^{T}b- \\beta )u$.</p>\n",
    "    \n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>b)</strong> Da parte anterior, conclui-se que a reflexão de $r_{0}$ sobre $\\mathcal{H}_{i}$ é $r_{i} = r_{0} - 2(A_{i*}r_{0}-b_{i})(A_{i*}^{T})$, e portanto, o valor médio de todas as reflexões $\\{r_{1}, r_{2}, \\ldots, r_{n}\\}$ é </p>\n",
    "   <p> \\begin{align}\n",
    "        m &= \\frac{1}{n}\\sum_{i=1}^{n}r_{i} = \\frac{1}{n}\\sum_{i=1}^{n}(r_{0}-2(A_{i*}r_{0}-b_{i})(A_{i*}^{T}))\\\\\n",
    "        &= r_{0} - \\frac{2}{n}\\sum_{i=1}^{n}(A_{i*}r_{0}-b_{i})(A_{i*})^{T}\\\\\n",
    "        &= r_{0} - \\frac{2}{n} A^{T}(Ar_{0} - b) = r_{0} - \\frac{2}{n}A^{T} \\varepsilon.\n",
    "    \\end{align}</p>\n",
    "       \n",
    "<p style=\"text-align: justify; text-justify: inter-word\"><strong>c)</strong> Primeiro note que \n",
    "    \\begin{align}\n",
    "    x - m_{k} &= x - m_{k-1} + \\frac{2}{n}A^{T} \\varepsilon_{k-1}\\\\\n",
    "    &= x - m_{k-1} + \\frac{2}{n}A^{T}(Am_{k-1} - b)\\\\\n",
    "    &= x - m_{k-1} + \\frac{2}{n}A^{T}(Am_{k-1} - Ax)\\\\\n",
    "    &= x - m_{k-1} + \\frac{2}{n}A^{T}A(m_{k-1} - x)\\\\\n",
    "    &= (I - \\frac{2}{n}A^{T}A)(x - m_{k-1}),\n",
    "    \\end{align}\n",
    "e então usando substituições sucessivas se conclui que $x - m_{k} = (I - \\frac{2}{n}A^{T}A)^{k}(x-m_{0})$.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Implementação Computacional </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reflexao (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Então, precisamos fazer uma função de reflexão\n",
    "function reflexao(p₀, u, β) \n",
    "    \n",
    "   return  2*proj(p₀, u, β) - p₀\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cimmino (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Cimmino(A, b; itmax=10000, ε= 1e-3)\n",
    "    n,r = size(A) \n",
    "    xₖ = ones(r)\n",
    "    k = 1 \n",
    "    A,b = normalize_matriz(A,b)\n",
    "    tol = norm(b- A*xₖ)\n",
    "    \n",
    "    while k <= itmax && tol> ε \n",
    "        rₖ = zeros(r)\n",
    "        for i=1:n\n",
    "         rₖ += reflexao(xₖ, A[i,:], b[i])\n",
    "        end\n",
    "        xₖ= rₖ/n\n",
    "        tol = norm(b- A*xₖ)\n",
    "        k += 1\n",
    "    end\n",
    "    return xₖ, tol, k\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07278968994792681, -0.039385854618292825, 0.12469450836399668, -0.2777793274599455, 1.1267132363887353, 0.7920233410340194, 0.33666095663170564, 0.13123579780334507, 0.07395673091775246, 0.7303097408385365  …  -0.19422691079925913, 0.6176740495933697, 0.8178942898139873, 0.3170120335404509, 1.2999353332230903, 0.5536919659364684, 0.37292251763582374, -0.26033103992332274, -0.34224436658768964, 1.22463219059066], 0.0009990975689428418, 3682)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cimmino(A, b, ε=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07261405615251051, -0.03916389608648503, 0.12489147942189936, -0.27798378677188956, 1.126993792259841, 0.7921229462266266, 0.33682600714817645, 0.13113307037510633, 0.07386776684659273, 0.7303309958069343  …  -0.19394417644898804, 0.6179881391565386, 0.8180255386480079, 0.3169940080058974, 1.3000104020820802, 0.5537583368723064, 0.37269526555555815, -0.2603750493400387, -0.3423281466707958, 1.2246971703556455], 0.0008687132737442782, 36)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kaczmarz(A, b, ε=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Referências</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word\">BENZI, Michele. <b>Gianfranco Cimmino’s contributions to Numerical Mathematics.</b> Atlanta, Georgia, 2005.</p>\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">CERQUEIRA, Ana Cecília Sanches. <b>Um estudo sobre sequências e séries.</b> 2013. Diss. (Mestrado) – Instituto de Geociências e Ciências Exatas, Universidade Estadual Paulista Júlio de Mesquita Filho, Rio Claro.</p>\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">ESTÁCIO, Leonardo Bravo. <b>Sobre a escolha da relaxação e ordenação dasprojeções no método de Kaczmarz com ênfase em implementações altamente paralelas e aplicações em reconstrução tomográfica.</b> 2014. Diss. (Mestrado) –Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos.</p>\n",
    "<p style=\"text-align: justify; text-justify: inter-word\">MEYER, Carl D. <b>Matrix analysis and Applied linear algebra.</b> Philadelphia:SIAM, 2000. p. 869.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
